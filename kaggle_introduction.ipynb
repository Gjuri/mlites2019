{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle_introduction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlites/mlites2019/blob/master/kaggle_introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "EeLteROCDzi7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Link to your Google Drive to enable import of data at ```/content/gdrive```\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vSp9f2X0ggwa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Introduction to Kaggle Datasets\n",
        "\n",
        "In this exercise, we'll learn how to get data into Colab\n",
        "\n",
        "First, we'll load up Google Drive\n",
        "\n",
        "Second, we'll search for data stored on Kaggle's servers\n",
        "\n",
        "Finally, we'll download the datasets we'll use in this course"
      ]
    },
    {
      "metadata": {
        "id": "8j_ZYrtGhBX0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Mounting Google Drive is easy"
      ]
    },
    {
      "metadata": {
        "id": "0JalKi1VB8mj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive # from PACKAGE import CLASS\n",
        "drive.mount('/content/gdrive') # mount your Google Drive to the /content/gdrive folder in your VM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kyyun7qbqZq6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setting up Kaggle is a bit more complicated\n",
        "[Setting up Kaggle in Colab](https://towardsdatascience.com/setting-up-kaggle-in-google-colab-ebb281b61463)\n",
        "\n",
        "1. Sign up for Kaggle if you're not already a member\n",
        "2. Go to _My Account_\n",
        "3. Go to _Create New API Token_\n",
        "4. That will download a file called **kaggle.json**\n",
        "5. Click *Files* -> *Upload* on the left and upload **kaggle.json**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "kcu2pIGhpxQb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# install kaggle package\n",
        "\n",
        "# pip is a python program for installing new packages\n",
        "# the ! indicates this command is to be run on the system's command line\n",
        "!pip install kaggle \n",
        "\n",
        "# set up key authentication\n",
        "!mkdir /content/kaggle #!mkdir is the system command to make a new directory\n",
        "!mkdir ~/.kaggle #the . makes it hidden, this is where our credentials will be stored\n",
        "\n",
        "# import json #import the json package which is often used to encode data for the web\n",
        "# token = {\"username\":\"YOUR-USER-NAME\",\"key\":\"SOME-VERY-LONG-STRING\"}\n",
        "# with open('~/.kaggle/kaggle.json', 'w') as file: #this says to save the string into a file\n",
        "#     json.dump(token, file)\n",
        "\n",
        "!mv /content/kaggle.json ~/.kaggle/kaggle.json #copy the file to a place that kaggle expects to find it\n",
        "!chmod 600 ~/.kaggle/kaggle.json #change the permissions to avoid leaking your credentials\n",
        "\n",
        "!kaggle config set -n path -v/content/kaggle #setup kaggle to use the /content/kaggle directory we made earlier\n",
        "!chmod 600 /root/.kaggle/kaggle.json #hide kaggle's copy of the credentials\n",
        "\n",
        "# finally, import the kaggle package\n",
        "\n",
        "import kaggle\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UpCVmBMkt8dV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Find Kaggle datasets of interest\n",
        "\n",
        "Kaggle package API details\n",
        "\n",
        "https://github.com/Kaggle/kaggle-api#datasets\n",
        "\n",
        "only the first 20 results are shown, additional pages can be shown with the --page flag"
      ]
    },
    {
      "metadata": {
        "id": "T_7sVX75sYnh",
        "colab_type": "code",
        "outputId": "d487312d-2b0e-4e01-dd40-e9f794615094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1142
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle datasets list --tags oceans #find datasets tagged with 'oceans'\n",
        "!kaggle datasets list --user noaa #find datasets by user 'NOAA'\n",
        "!kaggle datasets list --search environment --page 2 #find page 2 of datasets using search term 'environment'\n",
        "!kaggle datasets list --search alaska"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ref                                                           title                                            size  lastUpdated          downloadCount  \n",
            "------------------------------------------------------------  ----------------------------------------------  -----  -------------------  -------------  \n",
            "noaa/noaa-icoads                                              NOAA ICOADS                                     171GB  2018-03-13 17:37:47              0  \n",
            "noaa/deep-sea-corals                                          Deep Sea Corals                                  10MB  2017-08-28 17:11:03            409  \n",
            "uciml/el-nino-dataset                                         El Nino Dataset                                   3MB  2016-11-06 21:02:18           1006  \n",
            "teajay/global-shark-attacks                                   Global Shark Attacks                            548KB  2018-07-04 17:59:54           4540  \n",
            "noaa/seismic-waves                                            Tsunami Causes and Waves                        654KB  2017-02-03 04:15:19           1429  \n",
            "unt/disputed-territories                                      Disputed Territories and Wars, 1816-2001         95KB  2017-02-02 01:46:23            141  \n",
            "antgoldbloom/2016-kitefoil-race-results                       2016 and 2017 Kitefoil Race Results              87KB  2017-10-09 02:34:42            184  \n",
            "oewyn000/humpback-whale-fluke-keypoints                       Humpback Whale Fluke Keypoints                  168MB  2019-01-27 02:32:51             96  \n",
            "polinalemenkova/bathymetry-of-the-mariana-trench-25-profiles  Bathymetry of the Mariana Trench (25 profiles)   20KB  2018-12-09 04:30:50              4  \n",
            "sauuyer/alvin-dives                                           Alvin Dives                                     235KB  2018-05-04 16:11:43             19  \n",
            "ref                                                    title                                              size  lastUpdated          downloadCount  \n",
            "-----------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  \n",
            "noaa/ghcn-d                                            Daily Global Historical Climatology Network        99GB  2019-03-20 23:16:32              0  \n",
            "noaa/goes16                                            NOAA GOES-16                                       24GB  2019-03-20 23:20:37              0  \n",
            "noaa/noaa-icoads                                       NOAA ICOADS                                       171GB  2018-03-13 17:37:47              0  \n",
            "noaa/noaa-global-historical-climatology-network-daily  NOAA Global Historical Climatology Network Daily   14GB  2019-04-16 18:20:39            293  \n",
            "noaa/gsod                                              NOAA GSOD                                          26GB  2019-03-20 23:17:46              0  \n",
            "noaa/noaa-precipitation-15-minute                      NOAA Precipitation 15 Minute                      192MB  2019-04-17 15:05:30            283  \n",
            "noaa/deep-sea-corals                                   Deep Sea Corals                                    10MB  2017-08-28 17:11:03            409  \n",
            "noaa/severe-weather-data-inventory                     Severe Weather Data Inventory                     182MB  2016-10-24 15:34:45            959  \n",
            "noaa/hurricane-database                                Hurricanes and Typhoons, 1851-2014                928KB  2017-01-20 18:15:43           2564  \n",
            "noaa/global-historical-climatology-network             Global Historical Climatology Network               4MB  2016-10-24 15:23:05           1363  \n",
            "noaa/seismic-waves                                     Tsunami Causes and Waves                          654KB  2017-02-03 04:15:19           1429  \n",
            "noaa/noaa-severe-weather-data-inventory                NOAA Severe Weather Data Inventory                 18GB  2019-04-07 12:27:11             97  \n",
            "noaa/noaa-u-s-climatic-normals                         NOAA U.S. Climatic Normals                         10GB  2019-04-15 14:39:04             45  \n",
            "ref                                                           title                                             size  lastUpdated          downloadCount  \n",
            "------------------------------------------------------------  -----------------------------------------------  -----  -------------------  -------------  \n",
            "buntyshah/food-environment-atlas-data                         Food Environment Atlas Data                        5MB  2018-07-23 10:48:52             39  \n",
            "marshald/london-boroughs                                      London Borough Demographics                       10KB  2017-06-04 13:45:03            344  \n",
            "freedomhouse/press-freedom                                    Freedom of the Press, 2001-2015                   11KB  2017-02-03 23:30:16            307  \n",
            "usdot/nhtsa-traffic-fatalities                                US Traffic Fatality Records                      585MB  2019-03-20 23:21:02              0  \n",
            "olistbr/brazilian-ecommerce                                   Brazilian E-Commerce Public Dataset by Olist      42MB  2018-11-29 12:22:57          10625  \n",
            "ilknuricke/neurohackinginrimages                              Structural MRI Datasets (T1, T2, FLAIR etc.)     190MB  2017-01-04 20:01:18           2696  \n",
            "census/2013-american-community-survey                         2013 American Community Survey                   888MB  2017-05-01 19:10:03           3884  \n",
            "pitasr/scheduling-in-cloud-computing                          Scheduling in Cloud computing                     49KB  2017-06-11 22:07:18            311  \n",
            "regivm/kernel                                                 Manoeuvring Kaggle Kernel and Data Environment     7KB  2018-08-30 08:03:32              2  \n",
            "sohier/calcofi                                                CalCOFI                                           50MB  2017-08-23 19:24:53           2463  \n",
            "usda/a-year-of-pumpkin-prices                                 A Year of Pumpkin Prices                          16KB  2017-10-24 17:45:33           1461  \n",
            "sampadab17/network-intrusion-detection                        Network Intrusion Detection                      750KB  2018-10-09 09:39:37            239  \n",
            "lamdadev/state-wise-tree-cover-india                          State wise tree cover India                       971B  2016-11-10 17:25:47            149  \n",
            "residentmario/database-of-battles                             Historical Military Battles                      129KB  2017-09-13 20:39:07            669  \n",
            "edumagalhaes/quality-prediction-in-a-mining-process           Quality Prediction in a Mining Process            51MB  2017-12-06 21:16:37           1025  \n",
            "sohier/mussel-watch                                           Mussel Watch                                      11MB  2017-09-18 16:19:51            890  \n",
            "fschwartzer/tmd-dataset-5-seconds-sliding-window              TMD Dataset - 5 seconds sliding window             3MB  2019-02-05 18:08:10            142  \n",
            "ihmstefanini/industrial-safety-and-health-analytics-database  Industrial Safety and Health Analytics Database  160KB  2018-04-12 16:51:07            631  \n",
            "sasanj/virtual-reality-driving-simulator-dataset              Virtual Reality Driving Simulator Dataset          9MB  2017-08-16 14:06:11            158  \n",
            "wcukierski/2016-march-ml-mania                                2016 March ML Mania Predictions                   26MB  2017-11-15 22:36:48           1646  \n",
            "ref                                                title                                             size  lastUpdated          downloadCount  \n",
            "-------------------------------------------------  -----------------------------------------------  -----  -------------------  -------------  \n",
            "mcdonalds/nutrition-facts                          Nutrition Facts for McDonald's Menu                7KB  2017-03-03 13:30:58          11237  \n",
            "iditarod/iditarod-race                             2017 Iditarod Trail Sled Dog Race                 22KB  2017-03-22 15:04:59            168  \n",
            "noriuk/us-educational-finances                     U.S. Educational Finances                         83MB  2018-08-29 23:47:18           1848  \n",
            "rtatman/188-million-us-wildfires                   1.88 Million US Wildfires                        175MB  2017-09-13 22:41:53           3565  \n",
            "openaddresses/openaddresses-us-west                OpenAddresses - U.S. West                        816MB  2017-08-02 22:49:23            370  \n",
            "jamestollefson/alaskaairfields                     Alaska Airport Data                              266KB  2017-04-20 23:33:32            223  \n",
            "noriuk/us-education-datasets-unification-project   U.S. Education Datasets: Unification Project      85MB  2019-03-02 18:41:52           3457  \n",
            "cms/cms-american-indian-alaska-native-aian-health  CMS American Indian/Alaska Native (AIAN) Health  208KB  2019-04-15 03:30:17              8  \n",
            "jboysen/spy-plane-finder                           Spy Plane Finder                                  25MB  2017-08-11 19:13:10            284  \n",
            "hassenmorad/us-state-baby-names                    US State Baby Names                               41MB  2018-09-14 18:25:40             30  \n",
            "rec3141/biol342-genome-data                        Decontamination of Microbial Genomes              29MB  2019-04-17 16:32:31              1  \n",
            "theriley106/university-statistics                  University Statistics                             33KB  2018-01-21 23:03:55            570  \n",
            "madaha/people-without-internet                     People without internet                           60KB  2018-01-11 16:20:48            279  \n",
            "johnrvg/election1216                               Election 2016                                    630KB  2018-04-11 16:33:34            105  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tn5iOpLEv9H8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Iditarod dataset\n",
        "\n",
        "Now find the specific files you want and download them\n",
        "\n",
        "Let's see what files are available for the 2017 Iditarod dataset"
      ]
    },
    {
      "metadata": {
        "id": "vCWpgYW8wACG",
        "colab_type": "code",
        "outputId": "dbfc6700-f192-4341-c4c9-4ced75ce49fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle datasets files iditarod/iditarod-race"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name         size  creationDate         \n",
            "----------  -----  -------------------  \n",
            "report.csv  139KB  2017-03-22 15:03:30  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8oFjm_yzwonh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's download all the files, they'll show up in /content/kaggle/datasets"
      ]
    },
    {
      "metadata": {
        "id": "ktpZKadxwqg9",
        "colab_type": "code",
        "outputId": "13de8761-e901-4d6f-b1ab-33ec7206186b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle datasets download iditarod/iditarod-race"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading iditarod-race.zip to /content/kaggle/datasets/iditarod/iditarod-race\n",
            "\r  0% 0.00/21.5k [00:00<?, ?B/s]\n",
            "\r100% 21.5k/21.5k [00:00<00:00, 20.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZMIlCZctyq7A",
        "colab_type": "code",
        "outputId": "ed4d301f-88e2-4450-c47c-30706885c8ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#unzip the files\n",
        "!unzip /content/kaggle/datasets/iditarod/iditarod-race/iditarod-race.zip -d /content/kaggle/datasets/iditarod/iditarod-race/\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/kaggle/datasets/iditarod/iditarod-race/iditarod-race.zip\n",
            "  inflating: /content/kaggle/datasets/iditarod/iditarod-race/report.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "syUDb3mdzmPp",
        "colab_type": "code",
        "outputId": "115586ca-5b3c-43ac-93dc-e5075e4537c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#take a quick look\n",
        "\n",
        "import pandas as pd\n",
        "d = pd.read_csv('/content/kaggle/datasets/iditarod/iditarod-race/report.csv')\n",
        "d.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1146, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "J3dNlrGI2BdC",
        "colab_type": "code",
        "outputId": "b4eec634-d959-4f3f-cb4f-cfc1d8cbe5a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "d.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number</th>\n",
              "      <th>Name</th>\n",
              "      <th>Status</th>\n",
              "      <th>Country</th>\n",
              "      <th>Checkpoint</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Time</th>\n",
              "      <th>Speed</th>\n",
              "      <th>Arrival Date</th>\n",
              "      <th>Arrival Time</th>\n",
              "      <th>Arrival Dogs</th>\n",
              "      <th>Elapsed Time</th>\n",
              "      <th>Departure Date</th>\n",
              "      <th>Departure Time</th>\n",
              "      <th>Departure Dogs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Ryan Redington</td>\n",
              "      <td>Veteran</td>\n",
              "      <td>United States</td>\n",
              "      <td>Fairbanks</td>\n",
              "      <td>64.8321</td>\n",
              "      <td>-147.813</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>03/06/2017</td>\n",
              "      <td>11:00:00</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Otto Balogh</td>\n",
              "      <td>Rookie</td>\n",
              "      <td>Hungary</td>\n",
              "      <td>Fairbanks</td>\n",
              "      <td>64.8321</td>\n",
              "      <td>-147.813</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Misha Wiljes</td>\n",
              "      <td>Rookie</td>\n",
              "      <td>Czech Republic</td>\n",
              "      <td>Fairbanks</td>\n",
              "      <td>64.8321</td>\n",
              "      <td>-147.813</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>03/06/2017</td>\n",
              "      <td>11:04:00</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>Cody Strathe</td>\n",
              "      <td>Veteran</td>\n",
              "      <td>United States</td>\n",
              "      <td>Fairbanks</td>\n",
              "      <td>64.8321</td>\n",
              "      <td>-147.813</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>03/06/2017</td>\n",
              "      <td>11:06:00</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>Linwood Fiedler</td>\n",
              "      <td>Veteran</td>\n",
              "      <td>United States</td>\n",
              "      <td>Fairbanks</td>\n",
              "      <td>64.8321</td>\n",
              "      <td>-147.813</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>03/06/2017</td>\n",
              "      <td>11:08:00</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Number             Name   Status         Country Checkpoint  Latitude  \\\n",
              "0       2   Ryan Redington  Veteran   United States  Fairbanks   64.8321   \n",
              "1       3      Otto Balogh   Rookie         Hungary  Fairbanks   64.8321   \n",
              "2       4     Misha Wiljes   Rookie  Czech Republic  Fairbanks   64.8321   \n",
              "3       5     Cody Strathe  Veteran   United States  Fairbanks   64.8321   \n",
              "4       6  Linwood Fiedler  Veteran   United States  Fairbanks   64.8321   \n",
              "\n",
              "   Longitude  Distance  Time  Speed Arrival Date Arrival Time  Arrival Dogs  \\\n",
              "0   -147.813       NaN   0.0    NaN          NaN          NaN           NaN   \n",
              "1   -147.813       NaN   0.0    NaN          NaN          NaN           NaN   \n",
              "2   -147.813       NaN   0.0    NaN          NaN          NaN           NaN   \n",
              "3   -147.813       NaN   0.0    NaN          NaN          NaN           NaN   \n",
              "4   -147.813       NaN   0.0    NaN          NaN          NaN           NaN   \n",
              "\n",
              "   Elapsed Time Departure Date Departure Time  Departure Dogs  \n",
              "0           0.0     03/06/2017       11:00:00            16.0  \n",
              "1           NaN            NaN            NaN             NaN  \n",
              "2           0.0     03/06/2017       11:04:00            15.0  \n",
              "3           0.0     03/06/2017       11:06:00            16.0  \n",
              "4           0.0     03/06/2017       11:08:00            16.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "jxqykLVjSqEi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# BIOL342 Dataset\n",
        "\n",
        "Now we'll download the data that we'll use for examples in this course"
      ]
    },
    {
      "metadata": {
        "id": "X01qpm1kSpkB",
        "colab_type": "code",
        "outputId": "bf3de859-e398-45ea-990a-14ad287a84a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle datasets list --user rec3141\n",
        "!kaggle datasets files rec3141/biol342-genome-data\n",
        "!kaggle datasets download rec3141/biol342-genome-data\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ref                          title                                 size  lastUpdated          downloadCount  \n",
            "---------------------------  ------------------------------------  ----  -------------------  -------------  \n",
            "rec3141/biol342-genome-data  Decontamination of Microbial Genomes  29MB  2019-04-17 16:32:31              1  \n",
            "name                    size  creationDate         \n",
            "----------------------  ----  -------------------  \n",
            "biol342_cov_len_gc.tsv   6MB  2019-04-17 16:32:31  \n",
            "biol342_depths.tsv      43MB  2019-04-17 16:32:32  \n",
            "biol342_paired.tsv      12MB  2019-04-17 16:32:32  \n",
            "biol342_tax.tsv          5MB  2019-04-17 16:32:32  \n",
            "biol342_tnf.tsv         79MB  2019-04-17 16:32:28  \n",
            "Downloading biol342-genome-data.zip to /content/kaggle/datasets/rec3141/biol342-genome-data\n",
            " 31% 9.00M/29.4M [00:00<00:00, 27.0MB/s]\n",
            "100% 29.4M/29.4M [00:00<00:00, 66.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H4OBXQYvTLWG",
        "colab_type": "code",
        "outputId": "7fcd404a-be33-4e67-b5f1-78e0a55aa17b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip /content/kaggle/datasets/rec3141/biol342-genome-data/biol342-genome-data.zip -d ./"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/kaggle/datasets/rec3141/biol342-genome-data/biol342-genome-data.zip\n",
            "  inflating: ./biol342_paired.tsv    \n",
            "  inflating: ./biol342_tnf.tsv       \n",
            "  inflating: ./biol342_cov_len_gc.tsv  \n",
            "  inflating: ./biol342_tax.tsv       \n",
            "  inflating: ./biol342_depths.tsv    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DWJPplOjTd2b",
        "colab_type": "code",
        "outputId": "6f10a41c-9fc9-44cd-9055-a45257cbb3d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        }
      },
      "cell_type": "code",
      "source": [
        "covlengc = pd.read_csv('biol342_cov_len_gc.tsv',sep='\\t')\n",
        "covlengc.shape\n",
        "covlengc.head(25)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contig</th>\n",
              "      <th>student</th>\n",
              "      <th>cov</th>\n",
              "      <th>len</th>\n",
              "      <th>gc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>student0_1</td>\n",
              "      <td>student0</td>\n",
              "      <td>29.0114</td>\n",
              "      <td>255873</td>\n",
              "      <td>0.4995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>student0_2</td>\n",
              "      <td>student0</td>\n",
              "      <td>31.5053</td>\n",
              "      <td>190425</td>\n",
              "      <td>0.5151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>student0_3</td>\n",
              "      <td>student0</td>\n",
              "      <td>39.5121</td>\n",
              "      <td>149891</td>\n",
              "      <td>0.5077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>student0_4</td>\n",
              "      <td>student0</td>\n",
              "      <td>37.9206</td>\n",
              "      <td>135958</td>\n",
              "      <td>0.5212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>student0_5</td>\n",
              "      <td>student0</td>\n",
              "      <td>34.0143</td>\n",
              "      <td>121845</td>\n",
              "      <td>0.5204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>student0_6</td>\n",
              "      <td>student0</td>\n",
              "      <td>30.4397</td>\n",
              "      <td>117759</td>\n",
              "      <td>0.5067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>student0_7</td>\n",
              "      <td>student0</td>\n",
              "      <td>33.0765</td>\n",
              "      <td>114165</td>\n",
              "      <td>0.5210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>student0_8</td>\n",
              "      <td>student0</td>\n",
              "      <td>40.6539</td>\n",
              "      <td>112487</td>\n",
              "      <td>0.5224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>student0_9</td>\n",
              "      <td>student0</td>\n",
              "      <td>34.6739</td>\n",
              "      <td>97943</td>\n",
              "      <td>0.5203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>student0_10</td>\n",
              "      <td>student0</td>\n",
              "      <td>34.1807</td>\n",
              "      <td>96681</td>\n",
              "      <td>0.5237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>student0_11</td>\n",
              "      <td>student0</td>\n",
              "      <td>30.8479</td>\n",
              "      <td>93818</td>\n",
              "      <td>0.5095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>student0_12</td>\n",
              "      <td>student0</td>\n",
              "      <td>34.0987</td>\n",
              "      <td>92190</td>\n",
              "      <td>0.5030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>student0_13</td>\n",
              "      <td>student0</td>\n",
              "      <td>43.4598</td>\n",
              "      <td>88743</td>\n",
              "      <td>0.5262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>student0_14</td>\n",
              "      <td>student0</td>\n",
              "      <td>36.3573</td>\n",
              "      <td>85173</td>\n",
              "      <td>0.5128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>student0_15</td>\n",
              "      <td>student0</td>\n",
              "      <td>40.7952</td>\n",
              "      <td>83655</td>\n",
              "      <td>0.5075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>student0_16</td>\n",
              "      <td>student0</td>\n",
              "      <td>36.0454</td>\n",
              "      <td>83638</td>\n",
              "      <td>0.5089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>student0_17</td>\n",
              "      <td>student0</td>\n",
              "      <td>40.9907</td>\n",
              "      <td>83564</td>\n",
              "      <td>0.5165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>student0_18</td>\n",
              "      <td>student0</td>\n",
              "      <td>29.0636</td>\n",
              "      <td>83519</td>\n",
              "      <td>0.4990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>student0_19</td>\n",
              "      <td>student0</td>\n",
              "      <td>38.2118</td>\n",
              "      <td>81942</td>\n",
              "      <td>0.5101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>student0_20</td>\n",
              "      <td>student0</td>\n",
              "      <td>35.7632</td>\n",
              "      <td>80054</td>\n",
              "      <td>0.5127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>student0_21</td>\n",
              "      <td>student0</td>\n",
              "      <td>27.7239</td>\n",
              "      <td>79941</td>\n",
              "      <td>0.5105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>student0_22</td>\n",
              "      <td>student0</td>\n",
              "      <td>40.2678</td>\n",
              "      <td>73807</td>\n",
              "      <td>0.5160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>student0_23</td>\n",
              "      <td>student0</td>\n",
              "      <td>38.2217</td>\n",
              "      <td>66969</td>\n",
              "      <td>0.5249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>student0_24</td>\n",
              "      <td>student0</td>\n",
              "      <td>29.6679</td>\n",
              "      <td>63692</td>\n",
              "      <td>0.5088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>student0_25</td>\n",
              "      <td>student0</td>\n",
              "      <td>33.2767</td>\n",
              "      <td>62800</td>\n",
              "      <td>0.5232</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         contig   student      cov     len      gc\n",
              "0    student0_1  student0  29.0114  255873  0.4995\n",
              "1    student0_2  student0  31.5053  190425  0.5151\n",
              "2    student0_3  student0  39.5121  149891  0.5077\n",
              "3    student0_4  student0  37.9206  135958  0.5212\n",
              "4    student0_5  student0  34.0143  121845  0.5204\n",
              "5    student0_6  student0  30.4397  117759  0.5067\n",
              "6    student0_7  student0  33.0765  114165  0.5210\n",
              "7    student0_8  student0  40.6539  112487  0.5224\n",
              "8    student0_9  student0  34.6739   97943  0.5203\n",
              "9   student0_10  student0  34.1807   96681  0.5237\n",
              "10  student0_11  student0  30.8479   93818  0.5095\n",
              "11  student0_12  student0  34.0987   92190  0.5030\n",
              "12  student0_13  student0  43.4598   88743  0.5262\n",
              "13  student0_14  student0  36.3573   85173  0.5128\n",
              "14  student0_15  student0  40.7952   83655  0.5075\n",
              "15  student0_16  student0  36.0454   83638  0.5089\n",
              "16  student0_17  student0  40.9907   83564  0.5165\n",
              "17  student0_18  student0  29.0636   83519  0.4990\n",
              "18  student0_19  student0  38.2118   81942  0.5101\n",
              "19  student0_20  student0  35.7632   80054  0.5127\n",
              "20  student0_21  student0  27.7239   79941  0.5105\n",
              "21  student0_22  student0  40.2678   73807  0.5160\n",
              "22  student0_23  student0  38.2217   66969  0.5249\n",
              "23  student0_24  student0  29.6679   63692  0.5088\n",
              "24  student0_25  student0  33.2767   62800  0.5232"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "HiHbvcqXEGDT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import PyTorch, NumPy, MatPlotLib, and Pandas"
      ]
    },
    {
      "metadata": {
        "id": "fCgaFO54DpiQ",
        "colab_type": "code",
        "outputId": "7f20afb3-993b-4f0a-b6fc-ade8379419fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)\n",
        "print(\"done\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.3.0\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8PUhLbBnEJZG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}