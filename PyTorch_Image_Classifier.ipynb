{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_Image_Classifier_Final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "kmFYYBILsGAP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import PyTorch\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OLFfUZ_lsGE_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#upgrade and import Pillow (Python Imaging Library)\n",
        "!pip install Pillow==5.3.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5WRXBfHJsGIa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Run this cell to download the Udacity flower set\n",
        "!wget -cq https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
        "!unzip -qq flower_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z80-QQNDsGMk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5103e372-c509-42e4-eb45-17b9327c0897"
      },
      "cell_type": "code",
      "source": [
        "# Import resources\n",
        "\n",
        "#%matplotlib is a magic function in IPython. ... %matplotlib inline sets the backend of matplotlib to the 'inline' backend: With this backend, the output of plotting commands is displayed inline within frontends like the Jupyter notebook, directly below the code cell that produced it.\n",
        "%matplotlib inline\n",
        "\n",
        "# this enables higher-resolution figures\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import time #This module provides various time-related functions\n",
        "import json #JSON encoder and decoder\n",
        "import copy #Assignment statements in Python do not copy objects, they create bindings between a target and an object. For collections that are mutable or contain mutable items, a copy is sometimes needed so one can change one copy without changing the other. This module provides generic shallow and deep copy operations.\n",
        "\n",
        "import matplotlib.pyplot as plt #Matplotlib is a Python 2D plotting library which produces publication quality figures\n",
        "import seaborn as sns  #Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
        "import numpy as np #NumPy is the fundamental package for scientific computing with Python\n",
        "import PIL #the Python Imaging Library adds support for opening, manipulating, and saving many different image file format\n",
        "print(PIL.PILLOW_VERSION) #should be 5.3.0\n",
        "\n",
        "from PIL import Image #The Image module provides a class with the same name which is used to represent a PIL image. The module also provides a number of factory functions, including functions to load images from files, and to create new images.\n",
        "from collections import OrderedDict #This module implements specialized container datatypes providing alternatives to Python’s general purpose built-in containers, dict, list, set, and tuple.\n",
        "\n",
        "\n",
        "import torch #PyTorch is an open-source machine learning library for Python\n",
        "from torch import nn, optim #nn = Neural Network module, optim is a module implementing various optimization algorithms\n",
        "from torch.optim import lr_scheduler #provides several methods to adjust the learning rate based on the number of epochs\n",
        "from torch.autograd import Variable #Autograd is a PyTorch package for the differentiation for all operations on Tensors. It performs the backpropagation starting from a variable. In deep learning, this variable often holds the value of the cost function. backward executes the backward pass and computes all the backpropagation gradients automatically.\n",
        "import torchvision #consists of popular datasets, model architectures, and common image transformations for computer vision\n",
        "from torchvision import datasets, models, transforms #datasets= datasets, models= models, transforms=  common image transformations\n",
        "from torch.utils.data.sampler import SubsetRandomSampler #Samples elements randomly from a given list of indices, without replacement.\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F #The activation, dropout, etc. Modules in torch.nn are provided primarily to make it easy to use those operations in an nn.Sequential container. Otherwise it’s simplest to use the functional form for any operations that don’t have trainable or configurable parameters.\n",
        "\n",
        "import os #The OS module in Python provides a way of using operating system dependent functionality. \n",
        "\n",
        "print(\"ready\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.3.0\n",
            "ready\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EtzRpna1sGQz",
        "outputId": "9e1edf72-74a6-43b8-db7f-4ddcdb1459cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# check if GPU is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('Bummer!  Training on CPU ...')\n",
        "else:\n",
        "    print('You are good to go!  Training on GPU ...')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are good to go!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "baC8RfyxsGXY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NDQQeI0VsGch",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = 'flower_data'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "E6eJ9w9YsGi8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define your transforms for the training and testing sets\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Load the datasets with ImageFolder\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'valid']}\n",
        "\n",
        "# Using the image datasets and the trainforms, define the dataloaders\n",
        "batch_size = 64\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'valid']}\n",
        "\n",
        "class_names = image_datasets['train'].classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HBHkLjlYsGob",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
        "class_names = image_datasets['train'].classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0kk4MJbese6B",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(dataset_sizes)\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1Ci0fE8Tse9F",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Label mapping\n",
        "with open('cat_to_name.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "roAFvxS1sfAU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run this to test the data loader\n",
        "images, labels = next(iter(dataloaders['train']))\n",
        "images.size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LnxoYvW0sfGG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Run this to test your data loader\n",
        "images, labels = next(iter(dataloaders['train']))\n",
        "rand_idx = np.random.randint(len(images))\n",
        "# print(rand_idx)\n",
        "print(\"label: {}, class: {}, name: {}\".format(labels[rand_idx].item(),\n",
        "                                               class_names[labels[rand_idx].item()],\n",
        "                                               cat_to_name[class_names[labels[rand_idx].item()]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bLHN-uunsfMM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_name = 'densenet' #vgg\n",
        "if model_name == 'densenet':\n",
        "    model = models.densenet161(pretrained=True)\n",
        "    num_in_features = 2208\n",
        "    print(model)\n",
        "elif model_name == 'vgg':\n",
        "    model = models.vgg19(pretrained=True)\n",
        "    num_in_features = 25088\n",
        "    print(model.classifier)\n",
        "else:\n",
        "    print(\"Unknown model, please choose 'densenet' or 'vgg'\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Xxpu-O3bsfQJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create classifier\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "def build_classifier(num_in_features, hidden_layers, num_out_features):\n",
        "   \n",
        "    classifier = nn.Sequential()\n",
        "    if hidden_layers == None:\n",
        "        classifier.add_module('fc0', nn.Linear(num_in_features, 102))\n",
        "    else:\n",
        "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
        "        classifier.add_module('fc0', nn.Linear(num_in_features, hidden_layers[0]))\n",
        "        classifier.add_module('relu0', nn.ReLU())\n",
        "        classifier.add_module('drop0', nn.Dropout(.6))\n",
        "        classifier.add_module('relu1', nn.ReLU())\n",
        "        classifier.add_module('drop1', nn.Dropout(.5))\n",
        "        for i, (h1, h2) in enumerate(layer_sizes):\n",
        "            classifier.add_module('fc'+str(i+1), nn.Linear(h1, h2))\n",
        "            classifier.add_module('relu'+str(i+1), nn.ReLU())\n",
        "            classifier.add_module('drop'+str(i+1), nn.Dropout(.5))\n",
        "        classifier.add_module('output', nn.Linear(hidden_layers[-1], num_out_features))\n",
        "        \n",
        "    return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uJhshsnMsfJX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hidden_layers = None#[4096, 1024, 256][512, 256, 128]\n",
        "\n",
        "classifier = build_classifier(num_in_features, hidden_layers, 102)\n",
        "print(classifier)\n",
        "\n",
        " # Only train the classifier parameters, feature parameters are frozen\n",
        "if model_name == 'densenet':\n",
        "    model.classifier = classifier\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adadelta(model.parameters()) # Adadelta #weight optim.Adam(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    #optimizer_conv = optim.SGD(model.parameters(), lr=0.0001, weight_decay=0.001, momentum=0.9)\n",
        "    sched = optim.lr_scheduler.StepLR(optimizer, step_size=4)\n",
        "elif model_name == 'vgg':\n",
        "    model.classifier = classifier\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.0001)\n",
        "    sched = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
        "else:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "193_EfcLsfDz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adapted from https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "def train_model(model, criterion, optimizer, sched, num_epochs=5):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        #sched.step()\n",
        "                        loss.backward()\n",
        "                        \n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    #load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nkgn4OlRjleP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "model.to(device)\n",
        "model = train_model(model, criterion, optimizer, sched, epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "l5RW-Ixkjliv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "\n",
        "model.eval()\n",
        "\n",
        "accuracy = 0\n",
        "\n",
        "for inputs, labels in dataloaders['valid']:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    # Class with the highest probability is our predicted class\n",
        "    equality = (labels.data == outputs.max(1)[1])\n",
        "\n",
        "    # Accuracy is number of correct predictions divided by all predictions\n",
        "    accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
        "    \n",
        "print(\"Test accuracy: {:.3f}\".format(accuracy/len(dataloaders['valid'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DX_N0uf_jlmm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Saving the checkpoint\n",
        "model.class_to_idx = image_datasets['train'].class_to_idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5Da_x_lojlq3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint = {'input_size': 2208,\n",
        "              'output_size': 102,\n",
        "              'epochs': epochs,\n",
        "              'batch_size': 64,\n",
        "              'model': models.densenet161(pretrained=True),\n",
        "              'classifier': classifier,\n",
        "              'scheduler': sched,\n",
        "              'optimizer': optimizer.state_dict(),\n",
        "              'state_dict': model.state_dict(),\n",
        "              'class_to_idx': model.class_to_idx\n",
        "             }\n",
        "   \n",
        "torch.save(checkpoint, 'checkpoint_ic_d161.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KX27swgUjlu-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loading the checkpoint\n",
        "ckpt = torch.load('checkpoint_ic_d161.pth')\n",
        "ckpt.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rHnNzT33lpgs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "# If you are uploading this to the Udacity Lab, you may need this cell\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import models\n",
        "from collections import namedtuple\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import time\n",
        "import json\n",
        "import copy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import PIL\n",
        "\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "# If you used something other than 224x224 cropped images, set the correct size here\n",
        "image_size = 224\n",
        "# Values you used for normalizing the images. Default here are for\n",
        "# pretrained models from torchvision.\n",
        "norm_mean = [0.485, 0.456, 0.406]\n",
        "norm_std = [0.229, 0.224, 0.225]\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8qONYRG3lplp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load a checkpoint and rebuild the model\n",
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = checkpoint['model']\n",
        "    model.classifier = checkpoint['classifier']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    model.class_to_idx = checkpoint['class_to_idx']\n",
        "    optimizer = checkpoint['optimizer']\n",
        "    epochs = checkpoint['epochs']\n",
        "    \n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "        \n",
        "    return model, checkpoint['class_to_idx']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "e7RabGl4lprO",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model, class_to_idx = load_checkpoint('checkpoint_ic_d161.pth')\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "F9_HdGLFlpwM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx_to_class = { v : k for k,v in class_to_idx.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jzRYs7lrmE1f"
      },
      "cell_type": "markdown",
      "source": [
        "## Inference for Classification\n",
        "### Image Preprocessing"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "asCFxWf_lp1q",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_path = 'flower_data/valid/102/image_08006.jpg'\n",
        "img = Image.open(image_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-3zK4uQ6sB_n",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def process_image(image):\n",
        "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
        "        returns an Numpy array\n",
        "    '''\n",
        "    # Process a PIL image for use in a PyTorch model\n",
        "    # tensor.numpy().transpose(1, 2, 0)\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    image = preprocess(image)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgC5YYw1mNLq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def imshow(image, ax=None, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    \n",
        "    # PyTorch tensors assume the color channel is the first dimension\n",
        "    # but matplotlib assumes is the third dimension\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "    \n",
        "    # Undo preprocessing\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = std * image + mean\n",
        "    \n",
        "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
        "    image = np.clip(image, 0, 1)\n",
        "    \n",
        "    ax.imshow(image)\n",
        "    \n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aehqxsmumNR5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with Image.open('flower_data/valid/102/image_08006.jpg') as image:\n",
        "    plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TxAO8oDamYFY"
      },
      "cell_type": "markdown",
      "source": [
        "## Class Prediction"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-hQ_QhsomNPl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z8hdmpb1mbJz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.class_to_idx = image_datasets['train'].class_to_idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "akLYLOcnmgaJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict2(image_path, model, topk=5):\n",
        "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
        "    '''\n",
        "    \n",
        "    # Implement the code to predict the class from an image file\n",
        "    img = Image.open(image_path)\n",
        "    img = process_image(img)\n",
        "    \n",
        "    # Convert 2D image to 1D vector\n",
        "    img = np.expand_dims(img, 0)\n",
        "    \n",
        "    \n",
        "    img = torch.from_numpy(img)\n",
        "    \n",
        "    model.eval()\n",
        "    inputs = Variable(img).to(device)\n",
        "    logits = model.forward(inputs)\n",
        "    \n",
        "    ps = F.softmax(logits,dim=1)\n",
        "    topk = ps.cpu().topk(topk)\n",
        "    \n",
        "    return (e.data.numpy().squeeze().tolist() for e in topk)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1MMS4e_rmgso",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_path = 'flower_data/valid/18/image_04252.jpg'\n",
        "probs, classes = predict2(img_path, model.to(device))\n",
        "print(probs)\n",
        "print(classes)\n",
        "flower_names = [cat_to_name[class_names[e]] for e in classes]\n",
        "print(flower_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "P_rCY1n4mnCr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def view_classify(img_path, prob, classes, mapping):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    image = Image.open(img_path)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,10), ncols=1, nrows=2)\n",
        "    flower_name = mapping[img_path.split('/')[-2]]\n",
        "    ax1.set_title(flower_name)\n",
        "    ax1.imshow(image)\n",
        "    ax1.axis('off')\n",
        "    \n",
        "    y_pos = np.arange(len(prob))\n",
        "    ax2.barh(y_pos, prob, align='center')\n",
        "    ax2.set_yticks(y_pos)\n",
        "    ax2.set_yticklabels(flower_names)\n",
        "    ax2.invert_yaxis()  # labels read top-to-bottom\n",
        "    ax2.set_title('Class Probability')\n",
        "\n",
        "view_classify(img_path, probs, classes, cat_to_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "16f_Xr8gPpbI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}